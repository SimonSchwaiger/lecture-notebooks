{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb302e2-d1c0-4e28-bbe1-ce5d9864f171",
   "metadata": {},
   "source": [
    "# Basic Transformations for 2D Mobile Robots\n",
    "\n",
    "This notebook presents fundamental handling of transformations encountered with 2D mobile robots in Python and the Robot Operating System (ROS).\n",
    "Naming conventions generally adhere to the book *S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics [(link)](https://mitpress.mit.edu/9780262201629/probabilistic-robotics/)*.\n",
    "\n",
    "Presented conversions and code examples rely on the NumPy [(link)](https://numpy.org/) and Scipy Spatial [(link)](https://docs.scipy.org/doc/scipy/reference/spatial.html) libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f137c694-e819-4840-9626-1bf50aa4c1fe",
   "metadata": {},
   "source": [
    "# Table of Concents\n",
    "\n",
    "* [**Fundamentals**](#fundamentals)\n",
    "* [**Conventions for 2D Mobile Robots in ROS**](#conventions)\n",
    "    - [**Conversion to/from Rotation Matrices**](#2drotationmat)\n",
    "    - [**Conversion to/from ROS Pose**](#2drospose)\n",
    "* [**Transform Interfacing with ROS**](#rosinterfacing)\n",
    "    - [**Publishing Transforms**](#tfpublisher)\n",
    "    - [**Listening to Transforms**](#tflistener)\n",
    "\n",
    "## Fundamentals <a class=\"anchor\" id=\"fundamentals\"></a>\n",
    "\n",
    "Coordinate transformations are required in mobile robot programming as they create spatial relations between entities. They transform measurements taken relative to one coordinate frame to be relative to a different coordinate frame. In general, a transformation is depicted by a pose, consisting of a translation $T$ and rotation $R$ component.\n",
    "\n",
    "The translation component consists of three coordinates, which denote the offset along each axis ($x$, $y$, $z$). There are several representations of rotation in 3D, each with distinct advantages and disadvantages.\n",
    "\n",
    "* **Euler Angles**: This representation describes rotation as a sequence of three angles, typically denoted as rotations about the $x$, $y$, and $z$ axes (roll, pitch, yaw). Euler angles are intuitive but can suffer from issues like gimbal lock, where certain rotations become indistinguishable.\n",
    "\n",
    "    $$\n",
    "    \\begin{pmatrix}\n",
    "    x, y, z\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "\n",
    "* **Rotation Matrices**: A rotation matrix is a 3x3 matrix that represents rotation in three-dimensional space. This matrix can be applied to vectors to rotate them, and it is often used for combining multiple rotations. Rotation matrices are stable but can be cumbersome for certain operations, such as interpolation. The following example shows a rotation matrix for a 2D rotation of $\\theta$ around the $z$ axis.\n",
    "\n",
    "    $$\n",
    "    \\begin{pmatrix}\n",
    "    cos(\\theta), -sin(\\theta), 0\\\\\n",
    "    sin(\\theta), cos(\\theta), 0\\\\\n",
    "    0, 0, 1\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "\n",
    "* **Quaternions**: Quaternions are a four-dimensional representation that encodes rotation as an imaginary number ($x$, $y$, $z$, $w$). Contrary to euler angles, they are unambiguous and they are efficient in interpolating rotations. Furthermore, using quaternion multiplication, rotations can be easily combined. Note that $x$, $y$ and $z$ of quaternions are different from euler angles.\n",
    "\n",
    "    $$\n",
    "    \\begin{pmatrix}\n",
    "    x, y, z, w\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "\n",
    "# Conventions for 2D Mobile Robots in ROS <a class=\"anchor\" id=\"conventions\"></a>\n",
    "\n",
    "ROS natively uses quaterions to represent rotations, causing transforms to be represented using three values for translation and four values for rotation. However in ROS, 2D mobile robots usually move horizontally on the world's $xy$ plane and rotate around the world's (and the robot's) $z$ axis. Therefore, the robot pose can be simplified to three values: $(x, y, \\theta)$ with $x$ and $y$ denoting translation in the $xy$ plane and $\\theta$ denoting rotation around the $z$ axis. This representation is also refered to as the **robot state**. $\\theta$ is one of the euler angles.\n",
    "\n",
    "## Conversion to/from Rotation Matrices <a class=\"anchor\" id=\"2drotationmat\"></a>\n",
    "\n",
    "Since the rotation is performed around the $z$ axis, we can directly substitute the robot pose's components into the rotation matrix.\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "cos(\\theta), -sin(\\theta), x\\\\\n",
    "sin(\\theta), cos(\\theta), y\\\\\n",
    "0, 0, 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In oder to convert the matrix back to the robot pose, we can directly substitute the translation components. The rotation is retrieved using $atan2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c9c1c1-48db-47ce-b3f0-5c77fa448afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input pose: \n",
      "[0, 2, 3.1415] \n",
      "\n",
      "Rotation Matrix: \n",
      "[[-9.99999996e-01 -9.26535897e-05  0.00000000e+00]\n",
      " [ 9.26535897e-05 -9.99999996e-01  2.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "\n",
      "Output Pose: \n",
      "[0.     2.     3.1415]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pose2transform_matrix(pose):\n",
    "    x, y, theta = pose\n",
    "    return np.array([\n",
    "        [np.cos(theta), -np.sin(theta), x],\n",
    "        [np.sin(theta), np.cos(theta), y],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "def transform_matrix2pose(tf):\n",
    "    theta = np.arctan2(tf[1,0], tf[0,0])\n",
    "    return np.array([tf[0,2], tf[1,2], theta])\n",
    "\n",
    "# Transform pose to matrix and back to demonstrate the conversion\n",
    "pose = [0, 2, 3.1415]\n",
    "mat = pose2transform_matrix(pose)\n",
    "retpose = transform_matrix2pose(mat)\n",
    "\n",
    "print(\"Input pose: \\n{} \\n\\nRotation Matrix: \\n{} \\n\\nOutput Pose: \\n{}\".format(\n",
    "    pose, mat, retpose\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bab5e4-46d3-43bf-93fd-4c4de5ac1863",
   "metadata": {},
   "source": [
    "Transform matrices can easily be combined to a single transform by performing matrix multiplication. This is natively supported via the @ operator by the NumPy library [(link)](https://numpy.org/) used to create the rotation matrix in the example code.\n",
    "\n",
    "Let us assume a 2D mobile robot exists relative to a world frame with a goal deafined relative to the robot. The relation can be graphed as\n",
    "\n",
    "*world $\\to$ robot $\\to$ goal*\n",
    "\n",
    "with each arrow describing a transformation. The left arrow denotes the world to robot transform, while the right arrow depicts robot to goal. We can now calculate the goal's pose in world coordinates by converting both poses to transform matrices, performing matrix multiplication and converting them back to the state representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e43b564-cfad-42ff-835b-cebcceef98a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal pose relative to world: \n",
      "[-2.00009265  1.00018531 -1.57088531]\n"
     ]
    }
   ],
   "source": [
    "world2robot = [0, 2, 3.1415] # world2robot\n",
    "robot2goal = [2, 1, 1.5708] # robot2goal\n",
    "\n",
    "world2goal_mat = pose2transform_matrix(world2robot) @ pose2transform_matrix(robot2goal)\n",
    "world2goal = transform_matrix2pose(world2goal_mat)\n",
    "\n",
    "# Multiply transforms\n",
    "print(\"Goal pose relative to world: \\n{}\".format(\n",
    "    world2goal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527de7c-25f5-4049-911c-aae0b2b236c0",
   "metadata": {},
   "source": [
    "The arrows indicate that transformations are directional. This direction has to be considered when combining transformations. An easy to follow rule of thumb is to only multiply in direction of the arrow as shown in the previous example. Depending on how transforms are provided, it may be required to invert the transforms. This is achieved by inverting the matrix.\n",
    "\n",
    "Let us assume a similar example as previously, however, now the transformations from world to the robot and from world to the goal are given and the goal pose relative to the robot must be calculated.\n",
    "\n",
    "*robot $\\leftarrow$ world $\\to$ goal*\n",
    "\n",
    "In order to apply matrix multiplication, the robot to world transformation must be inverted as shon in the next example. The example uses NumPy's matrix inversion, whose documentation can be found [(here)](https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html). After inversion, the graph allows for the two transform matrices to be multiplied.\n",
    "\n",
    "*robot $\\to$ world $\\to$ goal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c054f496-e2ce-445b-9e58-2e92328100e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal pose relative to robot; \n",
      "[1.99990734 1.0001853  1.57088531]\n"
     ]
    }
   ],
   "source": [
    "world2robot = [0, 2, 3.1415]\n",
    "world2goal = [-2, 1, -1.5708]\n",
    "\n",
    "robot2world_mat = np.linalg.inv(pose2transform_matrix(world2robot))\n",
    "robot2goal_mat = robot2world_mat @ pose2transform_matrix(world2goal)\n",
    "robot2goal = transform_matrix2pose(robot2goal_mat)\n",
    "\n",
    "print(\"Goal pose relative to robot; \\n{}\".format(\n",
    "    robot2goal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8776bdf1-0a5e-4497-865a-140ca553f19d",
   "metadata": {},
   "source": [
    "## Conversion to/from ROS Pose <a class=\"anchor\" id=\"2drospose\"></a>\n",
    "\n",
    "In order to convert to and from the quaternions used by ROS to present a pose's rotation component, we use the SciPy Spatial library [(link)](https://docs.scipy.org/doc/scipy/reference/spatial.html). The following example uses ROS' Pose message [(link)](https://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/Pose.html), however the same concept for conversions applies to all transformation representations in ROS that use the *Point* and *Quaternion* messages for translation and roation respectively.\n",
    "\n",
    "The Point message depicting translation can be directly populated with the robot pose's $x$ and $y$ values and 0 for $z$. However, in order to populate the Pose's Quaternion component, we first instantiate a SciPy rotation instance from a single euler angle ($\\theta$ represents the rotation around $z$) and convert that directly to a quaternion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c73fdc-d1da-4275-b246-019c8614129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input pose: \n",
      "[0, 2, 3.1415] \n",
      "\n",
      "Rotation Matrix: \n",
      "position: \n",
      "  x: 0\n",
      "  y: 2\n",
      "  z: 0\n",
      "orientation: \n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  z: 0.999999998926914\n",
      "  w: 4.632679487995776e-05 \n",
      "\n",
      "Output Pose: \n",
      "[0.     2.     3.1415]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from geometry_msgs.msg import Pose, Point, Quaternion\n",
    "\n",
    "def pose2ROS(pose):\n",
    "    p = Pose()\n",
    "    p.position = Point(x=pose[0], y=pose[1], z=0)\n",
    "    quat = R.from_euler(\"z\", pose[2]).as_quat() # Euler to quaternion, scipy uses xyzw\n",
    "    p.orientation = Quaternion(x=quat[0], y=quat[1], z=quat[2], w=quat[3])\n",
    "    return p\n",
    "\n",
    "def ROS2pose(Pose_msg):\n",
    "    quat, point = Pose_msg.orientation, Pose_msg.position\n",
    "    theta = R.from_quat([quat.x, quat.y, quat.z, quat.w]).as_euler(\"xyz\")[2]\n",
    "    return np.array([point.x, point.y, theta])\n",
    "\n",
    "# Transform pose to ROS message and back to demonstrate the conversion\n",
    "pose = [0, 2, 3.1415]\n",
    "Pose_msg = pose2ROS(pose)\n",
    "retpose = ROS2pose(Pose_msg)\n",
    "\n",
    "print(\"Input pose: \\n{} \\n\\nRotation Matrix: \\n{} \\n\\nOutput Pose: \\n{}\".format(\n",
    "    pose, Pose_msg, retpose\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bd831-0f69-41a8-b0f2-2609b28020cb",
   "metadata": {},
   "source": [
    "# Transform Interfacing with ROS <a class=\"anchor\" id=\"rosinterfacing\"></a>\n",
    "\n",
    "This section provides example code how send and receive transformations to and from the Robot Operating System (ROS). While code using the `tf2_ros` module works in versions 1 and 2 of ROS, ROS node initialisation in the following examples uses ROS 1.\n",
    "\n",
    "To run the following code examples, make sure that your Jupyter notebook interface is installed in the same Python environment as ROS. Furthermore, a `roscore` must be running in the background.\n",
    "\n",
    "## Publishing Transforms <a class=\"anchor\" id=\"tfpublisher\"></a>\n",
    "\n",
    "In ROS, the `tf2_ros` package is used to keep track of multiple coordinate frames over time and to publish transformations between them. Transforms are published by creating a `tf2_ros.TransformBroadcaster` object serving as the connection to ROS' transformation system. The standard message type for transforms is `TransformStamped` [(documentation link)](https://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/TransformStamped.html). Similarly to the Pose message used in earlier examples, the main transform component consists of translation and rotation. Additionally, a `Header` [(documentation link)](https://docs.ros.org/en/noetic/api/std_msgs/html/msg/Header.html) message provides timing information and the transformation's reference frame.\n",
    "\n",
    "In ROS, transforms are referenced using a string called *frame_id*, representing a frame's name. All transforms in the ROS system form a tree, which can be visualised using *tf2_tools* [(link to tutorial)](https://wiki.ros.org/tf2/Tutorials/Introduction%20to%20tf2).\n",
    "\n",
    "**In order to be successfully published to ROS, a transform must be valid. This means, that at least the following message fields must be set:**\n",
    "\n",
    "* `transform.header.stamp`: Timestamp when the transform occured. Usually set to the current time using `rospy.Time.now()`\n",
    "* `transform.header.frame_id`: The transform's reference frame. Transforms are defined *frame_id $\\to$ child_frame_id*\n",
    "* `transform.child_frame_id`: The transform's child frame\n",
    "* (`transform.transform.rotation.w`: The transform's rotation must be a valid quaternion. Since all values in the transform are initialised with 0, the easiest way to achieve a valid rotation is to set the w component to 0. This will result in no rotation.)\n",
    "\n",
    "A `tf2_ros.TransformBroadcaster` object is created and allows publishing of transforms using the the `sendTransform` method. **In order to enable publishing of transforms, a ROS node has to be initialised before creating a TransformBroadcaster or TransformListener object.**\n",
    "\n",
    "For filling in the transform of the TransformStamped message, please refer to the section *Conversion to/from ROS Pose*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47514c5d-5524-4841-aa24-88cde1178bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geometry_msgs.msg import TransformStamped\n",
    "import tf2_ros\n",
    "import rospy\n",
    "import time\n",
    "\n",
    "rospy.init_node(\"basic_listener\") # Node initialisation required for comunication with ROS\n",
    "\n",
    "# Create transform\n",
    "transform = TransformStamped()\n",
    "\n",
    "# Add reference frame and set transform to occur at current time\n",
    "transform.header.frame_id = \"map\"\n",
    "transform.header.stamp = rospy.Time.now()\n",
    "\n",
    "# Define child frame and the relative transform\n",
    "# NOTE: The transform's rotation must be valid, therefore, w is set to 1 here\n",
    "transform.child_frame_id = \"my_new_transform\"\n",
    "transform.transform.translation.x = 5.\n",
    "transform.transform.rotation.w = 1.\n",
    "\n",
    "tfBuffer = tf2_ros.Buffer()\n",
    "broadcaster = tf2_ros.TransformBroadcaster()\n",
    "\n",
    "# Wait for buffer to be initialised\n",
    "time.sleep(4)\n",
    "\n",
    "broadcaster.sendTransform(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c7791-01fb-4bb4-8b15-b1c0c59fda3f",
   "metadata": {},
   "source": [
    "To visualise this code cell's output, open two terminals and run `roscore` and `rostopic echo /tf` respectively before executing the code cell. The second terminal will show the published transform on the */tf* topic used internally by ROS to keep track of transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38879ead-8a8e-4ab8-baaa-05e437b1c384",
   "metadata": {},
   "source": [
    "## Listening to Transforms <a class=\"anchor\" id=\"tflistener\"></a>\n",
    "\n",
    "Transformations can be read by creating a `tf2_ros.TransformListener` object from a `tf2_ros.Buffer`. This object contains the `lookup_transform` method, which lets users read the transform between two frames in a given time interval. The following example code waits indefinetly for a transformation from the map to the robot coordinate system to become available.\n",
    "\n",
    "The method's documentation can be found at [this link](https://docs.ros.org/en/indigo/api/tf2_ros/html/c++/classtf2__ros_1_1Buffer.html#acabbd72cae8f49fb3b6ede3be7e34c55). The main arguments we provide are the source and target frames the transform occurs between as well as a timeout of ten seconds that the method waits for the the transform to become available (`rospy.Duration(10.0)`). Furthermore, we specify the time in the ROS system of when the transform has occured. A time of zero indicates, that we want the latest transform (`rospy.Time(0)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a032e066-01fa-442a-a579-ed17a45c07c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform from /map to /my_new_transform: \n",
      "header: \n",
      "  seq: 0\n",
      "  stamp: \n",
      "    secs: 0\n",
      "    nsecs:         0\n",
      "  frame_id: \"map\"\n",
      "child_frame_id: \"my_new_transform\"\n",
      "transform: \n",
      "  translation: \n",
      "    x: 0.0\n",
      "    y: 0.0\n",
      "    z: 0.0\n",
      "  rotation: \n",
      "    x: 0.0\n",
      "    y: 0.0\n",
      "    z: 0.0\n",
      "    w: 1.0\n"
     ]
    }
   ],
   "source": [
    "tfBuffer = tf2_ros.Buffer()\n",
    "listener = tf2_ros.TransformListener(tfBuffer)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        transform = tfBuffer.lookup_transform('map', 'my_new_transform', rospy.Time(0), rospy.Duration(10.0))\n",
    "        break\n",
    "    except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):\n",
    "        print(\"Waiting for transform took longer than 10 sec\")\n",
    "        continue\n",
    "\n",
    "print(\"Transform from /map to /my_new_transform: \\n{}\".format(transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639592b7-f372-4d36-8905-8f216f49cd63",
   "metadata": {},
   "source": [
    "To test this code cell, open two terminals and run `roscore` and the following command respectively: \n",
    "\n",
    "```bash\n",
    "rostopic pub /tf tf2_msgs/TFMessage \"transforms:\n",
    "- header:\n",
    "    seq: 0\n",
    "    stamp:\n",
    "      secs: 0\n",
    "      nsecs: 0\n",
    "    frame_id: 'map'\n",
    "  child_frame_id: 'my_new_transform'\n",
    "  transform:\n",
    "    translation:\n",
    "      x: 0.0\n",
    "      y: 0.0\n",
    "      z: 0.0\n",
    "    rotation:\n",
    "      x: 0.0\n",
    "      y: 0.0\n",
    "      z: 0.0\n",
    "      w: 1.0\"      \n",
    "```\n",
    "\n",
    "The second command continuously publishes a simple transform to ROS' *tf* topic. After having starte the two terminals, run the previous code cell to initialise a ROS node. Finally, this code cell can be run to listen to and print the published transform. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
